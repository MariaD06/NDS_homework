{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8hAVX7FaKZq"
      },
      "source": [
        "# Homework 2: Fine-tuning & Prompting of LMs (51 points)\n",
        "\n",
        "The focus of this homework is on one prominent fine-tuning technique -- reinforcement learning from human feedback -- and on critically thinking about prompting techniques and papers about language models\n",
        "\n",
        "### Logistics\n",
        "\n",
        "* submission deadline: June 3rd th 23:59 German time via Moodle\n",
        "  * please upload a **SINGLE .IPYNB FILE named Surname_FirstName_HW2.ipynb** containing your solutions of the homework.\n",
        "* please solve and submit the homework **individually**!\n",
        "* if you use Colab, to speed up the execution of the code on Colab, you can use the available GPU (if Colab resources allow). For that, before executing your code, navigate to Runtime > Change runtime type > GPU > Save.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKUROgCSaKZt"
      },
      "source": [
        "## Exercise 1: Advanced prompting strategies (16 points)\n",
        "\n",
        "The lecture discussed various sophisticated ways of prompting language models for generating texts. Please answer the following questions about prompting techniques in context of different models, and write down your answers, briefly explaining them (max. 3 sentences). Feel free to actually try out some of the prompting strategies to play around with them and build your intuitions.\n",
        "\n",
        "> Consider the following language models:\n",
        "> * GPT-4, Qwen-2.5-Coder-32B, Mistral-24B-Instruct, Llama-2-70b-base.\n",
        ">  \n",
        "> Consider the following prompting / generation strategies:\n",
        "> * tree-of-thought reasoning, zero-shot chain-of-thought prompting, few-shot prompting, self-reflection prompting.\n",
        ">\n",
        "> For each model:\n",
        "> * which strategies do you think work well, and why?\n",
        ">\n",
        "> For each prompting strategy:\n",
        "> * Name an example task or context, and model, in which you would think they work best. Briefly justify why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3HoM6qtaKZt"
      },
      "source": [
        "## Exercise 2: RLHF for summarization (15 points)\n",
        "\n",
        "In this exercise, we want to fine-tune GPT-2 to generate human-like news summaries, following a procedure that is very similar to the example of the movie review generation from [sheet 4.1](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/04a-finetuning-RL.html). The exercise is based on the paper by [Ziegler et al. (2020)](https://arxiv.org/pdf/1909.08593).\n",
        "\n",
        "To this end, we will use the following components:\n",
        "* in order to initialize the policy, we use GPT-2 that was already fine-tuned for summarization, i.e., our SFT model is [this](https://huggingface.co/gavin124/gpt2-finetuned-cnn-summarization-v2)\n",
        "* as our reward model, we will use a task-specific reward signal, namely, the ROUGE score that evaluates a summary generated by a model against a human \"gold standard\" summary.\n",
        "* a dataset of CNN news texts and human-written summaries (for computing the rewards) for the fine-tuning which can be found [here](https://huggingface.co/datasets/abisee/cnn_dailymail). Please note that we will use the *validation* split because we only want to run short fine-tuning.\n",
        "\n",
        "**NOTE:** for building the datset and downloading the pretrained model, ~4GB of space will be used.\n",
        "\n",
        "> **YOUR TASK:**\n",
        ">\n",
        "> Your job for this task is to set up the **GRPO-based** training with the package `trl`, i.e., the set up step 3 of [this](https://cdn.openai.com/instruction-following/draft-20220126f/methods.svg) figure. GRPO (Group Relative Policy Optimization) is an RL algorithm that was proposed by [Shao et al. (2024)](https://arxiv.org/pdf/2402.03300) for the DeepSeek math model.\n",
        "> 1. Please complete the code or insert comments what a particular line of code does below where the comments says \"#### YOUR CODE / COMMENT HERE ####\". For this and for answering the questions, you might need to dig a bit deeper into the working of GRPO, the algorithm that we are using for training. You can find relevant information on the implementation, e.g., [here](https://huggingface.co/docs/trl/main/en/grpo_trainer).\n",
        "> 2. To test your implementation, you can run the training for ~250 steps, but you are NOT required to train the full model since it will take too long. We will NOT be evaluating your submission based on the performance of the model.\n",
        "> 3. Answer the questions below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCgZ-LN0aKZu",
        "outputId": "5b29d5c2-9831-4092-f717-2722be246b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gcsfs==2025.3.0 in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Requirement already satisfied: fsspec==2025.3.0 in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Requirement already satisfied: accelerate==1.6.0 in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: trl==0.17.0 in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.0) (3.11.15)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.0) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.0) (1.2.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.0) (2.19.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.0) (2.32.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0) (0.31.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0) (0.5.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl==0.17.0) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.17.0) (4.52.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.0) (1.20.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2025.3.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2025.3.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2025.3.0) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.6.0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2025.3.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2025.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2025.3.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2025.3.0) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.6.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl==0.17.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl==0.17.0) (0.21.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs==2025.3.0) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2025.3.0) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2025.3.0) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2025.3.0) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2025.3.0) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.17.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.17.0) (2.19.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2025.3.0) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2025.3.0) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2025.3.0) (1.26.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.17.0) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs==2025.3.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2025.3.0) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.6.0) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gcsfs==2025.3.0 fsspec==2025.3.0 accelerate==1.6.0 trl==0.17.0 evaluate rouge_score datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2oanAGi4aKZv"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "from trl import (\n",
        "    GRPOTrainer,\n",
        "    GRPOConfig,\n",
        ")\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t2zPkTc0aKZv"
      },
      "outputs": [],
      "source": [
        "#### YOUR COMMENT HERE (what is the purpose of this code?) ####\n",
        "\n",
        "# This code defines the training configuration for the GRPOTrainer.\n",
        "# It sets key hyperparameters like learning rate, number of training steps, batch size,\n",
        "# and how many candidate summaries to generate per prompt. These settings control how\n",
        "# the model is fine-tuned using the GRPO (Group Relative Policy Optimization) reinforcement learning algorithm.\n",
        "\n",
        "config = GRPOConfig(\n",
        "    #### YOUR COMMENT HERE (what is the meaning of each of the following parameters?) #####\n",
        "\n",
        "    #### learning_rate controls how big a step the optimizer takes during each update.\n",
        "    # A smaller value like 1.41e-5 ensures more stable updates during fine-tuning.\n",
        "    learning_rate=1.41e-5,\n",
        "    #### YOUR COMMENT HERE ####\n",
        "    #### max_steps is the total number of training steps to run. This limits the training run to 250 updates.\n",
        "    #max_steps=250,\n",
        "    max_steps=50,\n",
        "    #### YOUR COMMENT HERE ####\n",
        "    #### per_device_train_batch_size defines how many samples are passed through the model per device (e.g., per GPU) in each step.\n",
        "    per_device_train_batch_size=8,\n",
        "    #### YOUR COMMENT HERE####\n",
        "    #### num_generations defines how many candidate responses the model should generate per input prompt.\n",
        "    # These are used to calculate relative rewards in the GRPO algorithm.\n",
        "    #num_generations=2,\n",
        "    num_generations=8,\n",
        "    #### YOUR CODE HERE: set the number of overall training epochs to 1 ####\n",
        "    num_train_epochs=1,\n",
        "    #### YOUR COMMENT HERE####\n",
        "    #### logging_steps sets how often training metrics are logged. Here, it's every single step.\n",
        "    logging_steps=1,\n",
        "    #### YOUR COMMENT HERE####\n",
        "    #### report_to defines where logging should go (e.g., 'wandb', 'tensorboard', or 'none').\n",
        "    # 'none' is used to disable logging to external platforms.\n",
        "    report_to=\"none\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "105KyphCaKZw"
      },
      "source": [
        "We load the CNN dataset and truncate the texts to 512 tokens, because we don't want the training to be too memory heavy and we want to have \"available\" some tokens for the generation (GPT-2's context window size is 1024). Then we tokenize each text and pad it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yeW4wY_LaKZy"
      },
      "outputs": [],
      "source": [
        "def build_dataset(\n",
        "        model_name,\n",
        "        dataset_name=\"abisee/cnn_dailymail\"\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Build dataset for training. This builds the dataset from `load_dataset`.\n",
        "\n",
        "    Args:\n",
        "        model_name (`str`):\n",
        "            The name of the SFT model to be used, so that the matchin tokenizer can be loaded.\n",
        "        dataset_name (`str`):\n",
        "            The name of the dataset to be loaded.\n",
        "\n",
        "    Returns:\n",
        "        dataloader (`torch.utils.data.DataLoader`):\n",
        "            The dataloader for the dataset.\n",
        "    \"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = 'left'\n",
        "    # load the datasets\n",
        "    ds = load_dataset(dataset_name, '1.0.0', split=\"validation\")\n",
        "\n",
        "   # def tokenize(sample):\n",
        "        # single article string\n",
        "    #    sample[\"input_ids\"] = tokenizer.encode(\n",
        "    #        sample['article'],\n",
        "            #### YOUR CODE HERE (hint: inspect the dataset to see how to access the input text)####,\n",
        "     #       return_tensors=\"pt\",\n",
        "            #max_length=1024,\n",
        "      #      max_length=512,\n",
        "      #      truncation=True,\n",
        "       #     padding=\"max_length\"\n",
        "       # )\n",
        "\n",
        "#adjusted:\n",
        "    def tokenize(sample):\n",
        "        sample[\"input_ids\"] = tokenizer(\n",
        "            sample[\"article\"],\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=1024,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )[\"input_ids\"].squeeze(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # get the truncated natural language text, too\n",
        "        sample[\"prompt\"] = sample[\"article\"] ### your code here\n",
        "        sample[\"ground_truth\"] = sample[\"highlights\"] ### your code here\n",
        "        return sample\n",
        "\n",
        "    ds = ds.map(tokenize, batched=False)\n",
        "    ds.set_format(type=\"torch\")\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b6aac9791fb44853b8fc0d5a76172075",
            "33a94a39ba8a48569ea1c680f0e671d7",
            "5c4179cb84494eeca22d9b671c766ec6",
            "e37e3b19d9dc48aea84b03baf21f8874",
            "41675870bc784fb5a577891be3323a8c",
            "dec59b75979042e3b5cbe1568384a0ed",
            "17a6125970b248a595df3a901843bad8",
            "b5655a674c044c9e905db8444a0f6593",
            "339b61a2724f4abea809814bc9f08ea7",
            "a6c30d979ef6443ba6de1f798a5c17ac",
            "f9bc131cadff46bea48bb4c9d79eebc0"
          ]
        },
        "id": "FPk9_Il-aKZz",
        "outputId": "33ef6573-f2ed-4aaa-9244-a189eb8bc844"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/13368 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6aac9791fb44853b8fc0d5a76172075"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# use tokenizer from HF named: \"gavin124/gpt2-finetuned-cnn-summarization-v2\"\n",
        "# build the dataset\n",
        "dataset =  build_dataset(\"gavin124/gpt2-finetuned-cnn-summarization-v2\")\n",
        "\n",
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DoVx4bmaKZz",
        "outputId": "9829f014-f256-47f7-f563-2b0880bbdb41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'article': '(CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don\\'t know, but the fact that so many people can have a life extension, that\\'s pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for all the support and prayers,\" a comment on a Facebook page in her name read. \"I know this entire journey is much bigger than all of us. I also know I\\'m just the messenger.\" CNN cannot verify the authenticity of the page. But the power that multiplied Broussard\\'s gift was data processing of genetic profiles from donor-recipient pairs. It works on a simple swapping principle but takes it to a much higher level, according to California Pacific Medical Center in San Francisco. So high, that it is taking five surgeons, a covey of physician assistants, nurses and anesthesiologists, and more than 40 support staff to perform surgeries on 12 people. They are extracting six kidneys from donors and implanting them into six recipients. \"The ages of the donors and recipients range from 26 to 70 and include three parent and child pairs, one sibling pair and one brother and sister-in-law pair,\" the medical center said in a statement. The chain of surgeries is to be wrapped up Friday. In late March, the medical center is planning to hold a reception for all 12 patients. Here\\'s how the super swap works, according to California Pacific Medical Center. Say, your brother needs a kidney to save his life, or at least get off of dialysis, and you\\'re willing to give him one of yours. But then it turns out that your kidney is not a match for him, and it\\'s certain his body would reject it. Your brother can then get on a years-long waiting list for a kidney coming from an organ donor who died. Maybe that will work out -- or not, and time could run out for him. Alternatively, you and your brother could look for another recipient-living donor couple like yourselves -- say, two more siblings, where the donor\\'s kidney isn\\'t suited for his sister, the recipient. But maybe your kidney is a match for his sister, and his kidney is a match for your brother. So, you\\'d do a swap. That\\'s called a paired donation. It\\'s a bit of a surgical square dance, where four people cross over partners temporarily and everybody goes home smiling. But instead of a square dance, Broussard\\'s generous move set off a chain reaction, like dominoes falling. Her kidney, which was removed Thursday, went to a recipient, who was paired with a donor. That donor\\'s kidney went to the next recipient, who was also paired with a donor, and so on. On Friday, the last donor will give a kidney to someone who has been biding time on one of those deceased donor lists to complete the chain. Such long-chain transplanting is rare. It\\'s been done before, California Pacific Medical Center said in a statement, but matching up the people in the chain has been laborious and taken a long time. That changed when a computer programmer named David Jacobs received a kidney transplant. He had been waiting on a deceased donor list, when a live donor came along -- someone nice enough to give away a kidney to a stranger. Jacobs paid it forward with his programming skills, creating MatchGrid, a program that genetically matches up donor pairs or chains quickly. \"When we did a five-way swap a few years ago, which was one of the largest, it took about three to four months. We did this in about three weeks,\" Jacobs said. But this chain wouldn\\'t have worked so quickly without Broussard\\'s generosity -- or may not have worked at all. \"The significance of the altruistic donor is that it opens up possibilities for pairing compatible donors and recipients,\" said Dr. Steven Katznelson. \"Where there had been only three or four options, with the inclusion of the altruistic donor, we had 140 options to consider for matching donors and recipients.\" And that\\'s divine, Broussard\\'s friend Shirley Williams wrote in a comment her on Broussard\\'s Facebook page. \"You are a true angel my friend.\"', 'highlights': 'Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .', 'id': 'a4942dd663020ca54575471657a0af38d82897d6', 'input_ids': tensor([50256, 50256, 50256,  ...,   616,  1545,   526]), 'prompt': '(CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don\\'t know, but the fact that so many people can have a life extension, that\\'s pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for all the support and prayers,\" a comment on a Facebook page in her name read. \"I know this entire journey is much bigger than all of us. I also know I\\'m just the messenger.\" CNN cannot verify the authenticity of the page. But the power that multiplied Broussard\\'s gift was data processing of genetic profiles from donor-recipient pairs. It works on a simple swapping principle but takes it to a much higher level, according to California Pacific Medical Center in San Francisco. So high, that it is taking five surgeons, a covey of physician assistants, nurses and anesthesiologists, and more than 40 support staff to perform surgeries on 12 people. They are extracting six kidneys from donors and implanting them into six recipients. \"The ages of the donors and recipients range from 26 to 70 and include three parent and child pairs, one sibling pair and one brother and sister-in-law pair,\" the medical center said in a statement. The chain of surgeries is to be wrapped up Friday. In late March, the medical center is planning to hold a reception for all 12 patients. Here\\'s how the super swap works, according to California Pacific Medical Center. Say, your brother needs a kidney to save his life, or at least get off of dialysis, and you\\'re willing to give him one of yours. But then it turns out that your kidney is not a match for him, and it\\'s certain his body would reject it. Your brother can then get on a years-long waiting list for a kidney coming from an organ donor who died. Maybe that will work out -- or not, and time could run out for him. Alternatively, you and your brother could look for another recipient-living donor couple like yourselves -- say, two more siblings, where the donor\\'s kidney isn\\'t suited for his sister, the recipient. But maybe your kidney is a match for his sister, and his kidney is a match for your brother. So, you\\'d do a swap. That\\'s called a paired donation. It\\'s a bit of a surgical square dance, where four people cross over partners temporarily and everybody goes home smiling. But instead of a square dance, Broussard\\'s generous move set off a chain reaction, like dominoes falling. Her kidney, which was removed Thursday, went to a recipient, who was paired with a donor. That donor\\'s kidney went to the next recipient, who was also paired with a donor, and so on. On Friday, the last donor will give a kidney to someone who has been biding time on one of those deceased donor lists to complete the chain. Such long-chain transplanting is rare. It\\'s been done before, California Pacific Medical Center said in a statement, but matching up the people in the chain has been laborious and taken a long time. That changed when a computer programmer named David Jacobs received a kidney transplant. He had been waiting on a deceased donor list, when a live donor came along -- someone nice enough to give away a kidney to a stranger. Jacobs paid it forward with his programming skills, creating MatchGrid, a program that genetically matches up donor pairs or chains quickly. \"When we did a five-way swap a few years ago, which was one of the largest, it took about three to four months. We did this in about three weeks,\" Jacobs said. But this chain wouldn\\'t have worked so quickly without Broussard\\'s generosity -- or may not have worked at all. \"The significance of the altruistic donor is that it opens up possibilities for pairing compatible donors and recipients,\" said Dr. Steven Katznelson. \"Where there had been only three or four options, with the inclusion of the altruistic donor, we had 140 options to consider for matching donors and recipients.\" And that\\'s divine, Broussard\\'s friend Shirley Williams wrote in a comment her on Broussard\\'s Facebook page. \"You are a true angel my friend.\"', 'ground_truth': 'Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .'}\n"
          ]
        }
      ],
      "source": [
        "# inspect a sample of the dataset\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWGAcZKPaKZz"
      },
      "source": [
        "We load the tokenizer corresponsing to the SFT GPT2 model that we already used above to pretokenize the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "5cb8iR_taKZz"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gavin124/gpt2-finetuned-cnn-summarization-v2\")\n",
        "\n",
        "tokenizer.padding_side='left'\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVq7ZzEOaKZ0"
      },
      "source": [
        "Below, we define our custom reward function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "G9JuCLTMaKZ0"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "'''\n",
        "def reward_fn(\n",
        "        output: list[str],\n",
        "        original_summary: list[str]\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Computes the reward for each generated summary using the ROUGE-1 score.\n",
        "\n",
        "    Args:\n",
        "        output (list[str]): List of summaries generated by the model.\n",
        "        original_summary (list[str]): List of corresponding human-written summaries.\n",
        "\n",
        "    Returns:\n",
        "        scores (list[torch.Tensor]): List of ROUGE-1 scores (as tensors), one per summary.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    for o, s in list(zip(output, original_summary)):\n",
        "      score = rouge.compute(predictions=[o.strip()], references=[s])[\"rouge1\"]\n",
        "      scores.append(torch.tensor(score))\n",
        "\n",
        "    return scores\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "# adjusted reward function:\n",
        "def reward_fn(**kwargs):\n",
        "    output = kwargs[\"completions\"]\n",
        "    original_summary = kwargs[\"ground_truth\"]\n",
        "\n",
        "    scores = []\n",
        "    for o, s in zip(output, original_summary):\n",
        "        score = rouge.compute(predictions=[o.strip()], references=[s])[\"rouge1\"]\n",
        "        scores.append(torch.tensor(score))\n",
        "\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BmosxiKaKZ0"
      },
      "source": [
        "Nest, we set up the trainer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bxK2qCyIaKZ0"
      },
      "outputs": [],
      "source": [
        "### added by me\n",
        "# This wrapper maps trainer's keyword arguments to what reward_fn expects\n",
        "#def reward_fn_wrapper(**kwargs):\n",
        "#    return reward_fn(\n",
        "#        output=kwargs[\"completions\"],\n",
        "#        original_summary=kwargs[\"ground_truth\"]\n",
        "#    )\n",
        "###\n",
        "\n",
        "#### YOUR COMMENTS BELOW (what are the congle lines doing?) ####\n",
        "grpo_trainer = GRPOTrainer(\n",
        "    args=config,\n",
        "    model=\"gavin124/gpt2-finetuned-cnn-summarization-v2\",\n",
        "    #reward_funcs=reward_fn_wrapper,\n",
        "    reward_funcs=reward_fn,\n",
        "    processing_class=tokenizer,\n",
        "    train_dataset=dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training (required to produce logs) train for 50 steps\n",
        "grpo_trainer.train()\n",
        "\n",
        "# Now logs will exist\n",
        "print(grpo_trainer.state.log_history)"
      ],
      "metadata": {
        "id": "9dt1Q4m9T9Ao",
        "outputId": "011ee3f5-42d2-4f74-9c9a-5a513cf82574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-6a150dca5ac6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run training (required to produce logs) train for 50 steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrpo_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Now logs will exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrpo_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m                     )\n\u001b[1;32m   2554\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2555\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3737\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3739\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3741\u001b[0m             \u001b[0mloss_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmp_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/extras/profiling.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mprofiling_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/trainer/grpo_trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[0;34m(self, accumulated_local_batch)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgenerate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffered_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;31m# self._buffered_inputs=None can occur when resuming from a checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                 \u001b[0maccumulated_local_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_and_score_completions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulated_local_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 self._buffered_inputs = split_tensor_dict(\n\u001b[1;32m    901\u001b[0m                     \u001b[0maccumulated_local_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/trainer/grpo_trainer.py\u001b[0m in \u001b[0;36m_generate_and_score_completions\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    972\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather_deepspeed3_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds3_gather_for_generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             ) as unwrapped_model:\n\u001b[0;32m--> 974\u001b[0;31m                 prompt_completion_ids = unwrapped_model.generate(\n\u001b[0m\u001b[1;32m    975\u001b[0m                     \u001b[0mprompt_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2596\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2597\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2598\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_prefill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "-keFl2rWaKZ0",
        "outputId": "5e7dc0bd-edfb-4a39-b72a-96d0f4553857"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#### YOUR CODE HERE: plot the loss and the rewards of the model training by accessing the trainer logs under grpo_trainer.state.log_history ####\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# train the m\n",
        "\n",
        "\n",
        "\n",
        "# Extract logs\n",
        "logs = grpo_trainer.state.log_history\n",
        "\n",
        "# Collect step, loss, reward\n",
        "steps = [entry[\"step\"] for entry in logs if \"loss\" in entry]\n",
        "losses = [entry[\"loss\"] for entry in logs if \"loss\" in entry]\n",
        "rewards = [entry[\"reward\"] for entry in logs if \"reward\" in entry]\n",
        "\n",
        "# Plot loss\n",
        "plt.figure()\n",
        "plt.plot(steps, losses, label=\"Loss\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot reward\n",
        "plt.figure()\n",
        "plt.plot(steps, rewards, label=\"Reward\", color=\"green\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Reward\")\n",
        "plt.title(\"Training Reward\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### YOUR COMMENT HERE: do the plots indicate a trend towards successful training? ####\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grpo_trainer.state.log_history)\n"
      ],
      "metadata": {
        "id": "W9qnTUj3THeb",
        "outputId": "98a945f7-90f4-442d-d06c-5ac2f39202db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp9gv85GaKZ0"
      },
      "source": [
        "> **QUESTIONS:**\n",
        ">\n",
        "> 1. Suppose the plots of rewards below show training metrics for different runs of the summarization model training. Interpret what each of the plots tells us about training success; i.e., did the training run go well on this run? Do we expect to get good summaries? Why? Be concise!\n",
        "> 2. We have truncated the query articles to maximally 512 tokens. Given that we are using ROUGE with respect to ground truth summaries as a reward, why might this be problematic?\n",
        "> 3. GRPO is an algorithm improving over the PPO algorithm (Proximal Policy Optimization). What is they aspect that helps improve over PPO? Explain briefly.\n",
        "> 4. In the GRPO paper referenced above, on page 14, you can find the pseudo-algorithm for GRPO. For lines  1--4, 7--8 of the pseudo-code, write down what in our code above instatiates the concepts in the pseudo-code.\n",
        "> 5. In your own words, explain intuititvely what the role of the *group* in the algorithm is and why it is used. Use max. 3 sentences.\n",
        "> 6.  Name the parameter in the code above that determines the group size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_UQnai3aKZ0"
      },
      "source": [
        "![img](https://github.com/CogSciPrag/Understanding-LLMs-course/blob/main/understanding-llms/homework/data/rewards.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_q-EhcsaKZ1"
      },
      "source": [
        "## Exercise 3: First neural LM (20 points)\n",
        "\n",
        "Next to reading and understanding package documentations, a key skill for NLP researchers and practitioners is reading and critically assessing NLP literature. The density, but also the style of NLP literature has undergone a significant shift in the recent years with increasing acceleration of progress. Your task in this exercise is to read a paper about one of the first successful neural langauge models, understand its key architectural components and compare how these key components have evolved in modern systems that were discussed in the lecture.\n",
        "\n",
        "> Specifically, please read the paper by [Bengio et al. (2003)](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) and answer the following questions:\n",
        ">\n",
        "> * How were words / tokens represented? What is the difference / similarity to modern LLMs?\n",
        "> * How was the context represented? What is the difference / similarity to modern LLMs?\n",
        "> * What is the curse of dimensionality? Give a concrete example in the context of language modeling.\n",
        "> * Which training data was used? What is the difference / similarity to modern LLMs?\n",
        "> * Which components of the Bengio et al. (2003) model (if any) can be found in modern LMs?\n",
        ">\n",
        "\n",
        "Furthermore, your task is to carefully dissect the paper by Bengio et al. (2003) and analyse its structure and style in comparison to another more recent paper:  [Devlin et al. (2019) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805)\n",
        "\n",
        "**TASK:**\n",
        "\n",
        "> For each section of the Bengio et al. (2003) paper, what are key differences between the way it is written, the included contents, to the BERT paper (Devlin et al., 2019)? What are key similarities? Write max. 2 sentences per section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4InFSR_aKZ1"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "understanding_llms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b6aac9791fb44853b8fc0d5a76172075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33a94a39ba8a48569ea1c680f0e671d7",
              "IPY_MODEL_5c4179cb84494eeca22d9b671c766ec6",
              "IPY_MODEL_e37e3b19d9dc48aea84b03baf21f8874"
            ],
            "layout": "IPY_MODEL_41675870bc784fb5a577891be3323a8c"
          }
        },
        "33a94a39ba8a48569ea1c680f0e671d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec59b75979042e3b5cbe1568384a0ed",
            "placeholder": "",
            "style": "IPY_MODEL_17a6125970b248a595df3a901843bad8",
            "value": "Map:100%"
          }
        },
        "5c4179cb84494eeca22d9b671c766ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5655a674c044c9e905db8444a0f6593",
            "max": 13368,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_339b61a2724f4abea809814bc9f08ea7",
            "value": 13368
          }
        },
        "e37e3b19d9dc48aea84b03baf21f8874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c30d979ef6443ba6de1f798a5c17ac",
            "placeholder": "",
            "style": "IPY_MODEL_f9bc131cadff46bea48bb4c9d79eebc0",
            "value": "13368/13368[01:14&lt;00:00,210.42examples/s]"
          }
        },
        "41675870bc784fb5a577891be3323a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec59b75979042e3b5cbe1568384a0ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a6125970b248a595df3a901843bad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5655a674c044c9e905db8444a0f6593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "339b61a2724f4abea809814bc9f08ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6c30d979ef6443ba6de1f798a5c17ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9bc131cadff46bea48bb4c9d79eebc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}